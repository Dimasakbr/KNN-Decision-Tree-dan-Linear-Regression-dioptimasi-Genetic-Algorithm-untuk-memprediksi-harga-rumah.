{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LAPORAN TUGAS BESAR KECERDASAN ARTIFISIAL\n",
        "### Penerapan Algoritma K-Nearest Neighbors (KNN), Decision Tree, dan Linear Regression dengan Optimasi Genetic Algorithm (GA) untuk Prediksi Harga Rumah\n",
        "*House Price Regression Dataset*"
      ],
      "metadata": {
        "id": "aqXePWYL2754"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anggota Kelompok\n",
        "\n",
        "* Dimas Muhammad akbar(103012300155)\n",
        "* Muhammad Iqbal Tsany Putra (103012300397)\n",
        "* Arya Danuharja (103012300325)\n",
        "\n",
        "Mata Kuliah: CAK3DAB3 - Kecerdasan Artifisial  \n",
        "Kelas:  IF-47-01\n"
      ],
      "metadata": {
        "id": "PlLJpg723G-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. PENDAHULUAN"
      ],
      "metadata": {
        "id": "zviCWdBNELOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Latar Belakang"
      ],
      "metadata": {
        "id": "gFal97IdEjrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediksi harga rumah merupakan aspek penting dalam sektor properti karena dipengaruhi oleh berbagai faktor seperti karakteristik bangunan, lokasi, dan kondisi ekonomi. Akurasi prediksi sangat dibutuhkan oleh pembeli untuk menilai kewajaran harga, oleh penjual untuk menentukan harga yang kompetitif, oleh investor untuk mengidentifikasi peluang apresiasi nilai, serta oleh lembaga keuangan dalam menilai risiko kredit KPR.\n",
        "\n",
        "Pemanfaatan Kecerdasan Artifisial, khususnya machine learning, memungkinkan prediksi harga rumah yang lebih objektif dan akurat dibandingkan metode tradisional. Pendekatan ini mampu menganalisis pola kompleks dari data historis secara konsisten. Dalam penelitian ini, digunakan tiga algoritma machine learning—K-Nearest Neighbors, Decision Tree, dan Linear Regression—yang performanya dibandingkan dan dioptimasi menggunakan Genetic Algorithm melalui proses feature selection dan hyperparameter tuning."
      ],
      "metadata": {
        "id": "8QhH84qHE9Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Penjelasan Algoritma\n",
        "\n",
        "Untuk mencapai akurasi prediksi yang optimal, penelitian ini mengintegrasikan tiga algoritma machine learning utama yang dioptimasi menggunakan Genetic Algorithm:\n",
        "\n",
        "### 1.2.1 K-Nearest Neighbors (KNN)\n",
        "\n",
        "KNN adalah algoritma berbasis *instance-based learning* yang bekerja dengan prinsip kemiripan data. Algoritma ini memprediksi nilai target suatu data baru dengan melihat karakteristik tetangga terdekatnya dalam ruang fitur multidimensi.\n",
        "\n",
        "Cara Kerja KNN untuk Regresi:\n",
        "1. Menghitung jarak antara data baru dengan seluruh data training\n",
        "2. Memilih K tetangga terdekat berdasarkan jarak terkecil\n",
        "3. Menghitung rata-rata (atau rata-rata tertimbang) nilai target dari K tetangga tersebut\n",
        "4. Hasil rata-rata menjadi nilai prediksi untuk data baru\n",
        "\n",
        "Metrik Jarak yang Digunakan:\n",
        "- Euclidean Distance: $d = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$ — Jarak garis lurus dalam ruang multidimensi\n",
        "- Manhattan Distance: $d = \\sum_{i=1}^{n}|x_i - y_i|$ — Jumlah selisih absolut setiap dimensi\n",
        "\n",
        "Parameter Penting:\n",
        "- n_neighbors (K): Jumlah tetangga yang dipertimbangkan. K kecil → sensitif terhadap noise, K besar → lebih smooth tapi kurang detail\n",
        "- weights: `uniform` (semua tetangga sama pentingnya) atau `distance` (tetangga lebih dekat lebih berpengaruh)\n",
        "- p: Menentukan metrik jarak (p=1 Manhattan, p=2 Euclidean)\n",
        "\n",
        "\n",
        "\n",
        "### 1.2.2 Decision Tree\n",
        "\n",
        "Decision Tree adalah algoritma yang membangun model prediksi dalam bentuk struktur pohon keputusan. Algoritma ini bekerja dengan membagi data secara rekursif berdasarkan fitur yang paling informatif.\n",
        "\n",
        "Cara Kerja Decision Tree untuk Regresi:\n",
        "1. Memilih fitur dan threshold terbaik untuk membagi data (berdasarkan kriteria seperti MSE)\n",
        "2. Membagi data menjadi dua subset berdasarkan kondisi tersebut\n",
        "3. Mengulangi proses secara rekursif pada setiap subset\n",
        "4. Berhenti ketika mencapai kondisi tertentu (max depth, min samples, dll)\n",
        "5. Prediksi = rata-rata nilai target pada leaf node\n",
        "\n",
        "Parameter Penting:\n",
        "- max_depth: Kedalaman maksimum pohon. Terlalu dalam → overfitting, terlalu dangkal → underfitting\n",
        "- min_samples_split: Minimum sampel yang diperlukan untuk melakukan split\n",
        "- min_samples_leaf: Minimum sampel yang harus ada di setiap leaf node\n",
        "- criterion: Fungsi untuk mengukur kualitas split (`squared_error` atau `absolute_error`)\n",
        "\n",
        "Kelebihan: Mudah diinterpretasi, tidak memerlukan scaling, dapat menangkap hubungan non-linear\n",
        "\n",
        "Kekurangan: Rentan overfitting jika tidak dikontrol dengan baik\n",
        "\n",
        "### 1.2.3 Linear Regression\n",
        "\n",
        "Linear Regression adalah algoritma yang memodelkan hubungan linear antara variabel independen (fitur) dan variabel dependen (target).\n",
        "\n",
        "Formula Model:\n",
        "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n",
        "\n",
        "Dimana:\n",
        "- $\\hat{y}$ = nilai prediksi (harga rumah)\n",
        "- $\\beta_0$ = intercept (konstanta)\n",
        "- $\\beta_i$ = koefisien untuk fitur ke-i\n",
        "- $x_i$ = nilai fitur ke-i\n",
        "\n",
        "Cara Kerja:\n",
        "1. Mencari nilai koefisien ($\\beta$) yang meminimalkan Sum of Squared Errors (SSE)\n",
        "2. Menggunakan metode Ordinary Least Squares (OLS) atau gradient descent\n",
        "3. Prediksi dilakukan dengan mensubstitusi nilai fitur ke dalam persamaan\n",
        "\n",
        "Kelebihan: Sederhana, cepat, mudah diinterpretasi, tidak overfitting jika data linear\n",
        "\n",
        "Kekurangan: Hanya dapat menangkap hubungan linear, sensitif terhadap outlier\n",
        "\n",
        "\n",
        "### 1.2.4 Genetic Algorithm (GA)\n",
        "\n",
        "Genetic Algorithm adalah metode optimasi yang terinspirasi dari proses evolusi biologis. GA digunakan untuk mencari solusi optimal dari ruang pencarian yang besar.\n",
        "\n",
        "Komponen Utama GA:\n",
        "\n",
        "| Komponen | Analogi Biologis | Fungsi dalam ML |\n",
        "|----------|------------------|------------------|\n",
        "| Kromosom | DNA | Representasi solusi (kombinasi fitur + hyperparameter) |\n",
        "| Gen | Gen dalam DNA | Setiap elemen dalam kromosom (1 fitur atau 1 parameter) |\n",
        "| Populasi | Populasi makhluk hidup | Kumpulan kandidat solusi |\n",
        "| Fitness | Kemampuan bertahan | Performa model (RMSE validation) |\n",
        "| Seleksi | Seleksi alam | Memilih individu terbaik untuk reproduksi |\n",
        "| Crossover | Perkawinan | Menggabungkan gen dari 2 parent |\n",
        "| Mutasi | Mutasi genetik | Perubahan random pada gen |\n",
        "| Elitisme | Survivor | Menjaga individu terbaik tetap ada |\n",
        "\n",
        "Proses Evolusi GA:\n",
        "1. Inisialisasi populasi random\n",
        "2. Evaluasi fitness setiap individu\n",
        "3. LOOP selama n generasi:\n",
        "   a. Seleksi parent (tournament selection)\n",
        "   b. Crossover untuk menghasilkan offspring\n",
        "   c. Mutasi pada offspring\n",
        "   d. Evaluasi fitness offspring\n",
        "   e. Elitisme: pertahankan individu terbaik\n",
        "4. Return individu dengan fitness terbaik\n",
        "\n",
        "Penggunaan GA dalam Penelitian Ini:\n",
        "- Feature Selection: Memilih subset fitur terbaik (bit mask: 1 = gunakan, 0 = tidak)\n",
        "- Hyperparameter Tuning: Mencari kombinasi parameter optimal untuk setiap model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n-EmGbo3THH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Rumusan Masalah"
      ],
      "metadata": {
        "id": "rmlfO0hW1arA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan latar belakang yang telah diuraikan, penelitian ini merumuskan beberapa permasalahan utama yang akan dijawab:\n",
        "\n",
        "1. Bagaimana membangun model machine learning yang dapat memprediksi harga rumah dengan akurat?\n",
        "   - Investigasi karakteristik data dan hubungan antar variabel\n",
        "   - Pemilihan algoritma yang sesuai dengan karakteristik data\n",
        "   - Evaluasi performa model menggunakan metrik yang tepat\n",
        "\n",
        "2. Bagaimana Genetic Algorithm dapat digunakan untuk mengoptimasi pemilihan fitur dan hyperparameter model?\n",
        "   - Desain representasi kromosom yang efektif\n",
        "   - Penentuan parameter GA yang optimal\n",
        "   - Analisis konvergensi proses evolusi\n",
        "\n",
        "3. Model mana yang memberikan performa terbaik untuk kasus prediksi harga rumah?\n",
        "   - Perbandingan tiga algoritma: KNN, Decision Tree, dan Linear Regression\n",
        "   - Analisis trade-off antara kompleksitas dan akurasi\n",
        "   - Evaluasi kemampuan generalisasi pada data testing\n"
      ],
      "metadata": {
        "id": "y_yrBMf21hY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Tujuan"
      ],
      "metadata": {
        "id": "8k1Q46jV1ktX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penelitian ini bertujuan untuk:\n",
        "\n",
        "1. Mengimplementasikan tiga model machine learning untuk prediksi harga rumah:\n",
        "   - K-Nearest Neighbors (KNN): Model berbasis instance yang memprediksi berdasarkan kemiripan dengan data training\n",
        "   - Decision Tree: Model berbasis aturan yang membuat keputusan berdasarkan pemisahan fitur\n",
        "   - Linear Regression: Model yang mengasumsikan hubungan linear antara fitur dan target\n",
        "\n",
        "2. Menggunakan Genetic Algorithm (GA) untuk optimasi otomatis:\n",
        "   - Feature Selection: Memilih subset fitur yang paling relevan dan menghilangkan fitur yang tidak berkontribusi atau redundan\n",
        "   - Hyperparameter Tuning: Mencari kombinasi parameter optimal untuk setiap model tanpa exhaustive search\n",
        "\n",
        "3. Membandingkan performa ketiga model dan menentukan model terbaik berdasarkan:\n",
        "   - Metrik evaluasi: RMSE, MAE, R², MAPE\n",
        "   - Kemampuan generalisasi pada data yang belum pernah dilihat\n",
        "   - Analisis overfitting dan stabilitas prediksi\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wpXeQ6jg1oFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. SUMBER DAN PAPARAN DATA"
      ],
      "metadata": {
        "id": "UaySzFEO12HQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Sumber Dataset"
      ],
      "metadata": {
        "id": "Lg_1U0Nl17Yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data yang digunakan dalam penelitian ini berasal dari House Price Regression Dataset. Dataset ini dipilih karena memiliki karakteristik yang representatif untuk kasus prediksi harga properti.\n",
        "\n",
        "Link dataset : https://www.kaggle.com/datasets/prokshitha/home-value-insights\n",
        "\n",
        "Informasi Dataset:\n",
        "- Nama: House Price Regression Dataset\n",
        "- Sumber: Kaggle - Platform dataset untuk machine learning\n",
        "- Tipe Masalah: Regresi (memprediksi nilai kontinu)\n",
        "- Jumlah Data: 1.000 baris (sampel rumah)\n",
        "- Jumlah Variabel: 8 kolom (7 fitur + 1 target)\n",
        "\n",
        "Dataset ini cocok untuk eksperimen karena:\n",
        "1. Ukuran data cukup untuk training dan evaluasi model\n",
        "2. Fitur-fitur yang tersedia relevan dengan faktor penentu harga rumah\n",
        "3. Data sudah bersih (tidak ada missing values)\n"
      ],
      "metadata": {
        "id": "KCCITTNX2Ake"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Deskripsi Variabel"
      ],
      "metadata": {
        "id": "PuCdWvtQ2BWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset ini memiliki 7 variabel prediktor (fitur) dan 1 variabel target. Berikut adalah penjelasan detail untuk setiap variabel:\n",
        "\n",
        "| No | Variabel | Tipe | Satuan | Deskripsi |\n",
        "|:--:|:---------|:-----|:-------|:----------|\n",
        "| 1 | Square_Footage | Numerik (int) | sq ft | Luas bangunan dalam satuan kaki persegi. Fitur ini umumnya memiliki korelasi kuat dengan harga rumah. |\n",
        "| 2 | Num_Bedrooms | Numerik (int) | unit | Jumlah kamar tidur dalam rumah. Lebih banyak kamar tidur biasanya meningkatkan nilai properti. |\n",
        "| 3 | Num_Bathrooms | Numerik (int) | unit | Jumlah kamar mandi dalam rumah. Fasilitas kamar mandi mempengaruhi kenyamanan dan nilai rumah. |\n",
        "| 4 | Year_Built | Numerik (int) | tahun | Tahun rumah dibangun. Rumah baru umumnya memiliki harga lebih tinggi, namun rumah antik juga bisa bernilai tinggi. |\n",
        "| 5 | Lot_Size | Numerik (float) | acre | Luas tanah/kavling dalam satuan acre. Tanah yang lebih luas memberikan nilai tambah pada properti. |\n",
        "| 6 | Garage_Size | Numerik (int) | mobil | Kapasitas garasi dalam jumlah mobil (0, 1, atau 2). Garasi merupakan fasilitas yang dicari pembeli. |\n",
        "| 7 | Neighborhood_Quality | Numerik (int) | skala 1-10 | Skor kualitas lingkungan sekitar. Lingkungan yang baik meningkatkan nilai properti. |\n",
        "| 8 | House_Price | Numerik (float) | USD ($) | TARGET - Harga jual rumah dalam dolar Amerika. |\n",
        "\n",
        "Catatan: Semua variabel sudah dalam bentuk numerik sehingga tidak diperlukan proses encoding untuk data kategorikal.\n"
      ],
      "metadata": {
        "id": "j821kbwY2MIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Target Variabel"
      ],
      "metadata": {
        "id": "PgSgiG6k2Onu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variabel yang akan diprediksi dalam penelitian ini adalah House_Price (Harga Rumah).\n",
        "\n",
        "Karakteristik Target:\n",
        "- Nama Variabel: `House_Price`\n",
        "- Tipe Data: Kontinyu (numerik float)\n",
        "- Satuan: USD (Dolar Amerika Serikat)\n",
        "- Rentang Nilai: \\$111,627 - \\$1,108,237\n",
        "\n",
        "Karena target bersifat kontinyu (bukan kategori), maka masalah ini termasuk dalam kategori regresi, bukan klasifikasi. Metrik evaluasi yang digunakan akan berfokus pada pengukuran error prediksi seperti RMSE, MAE, dan R².\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NwQ9Apvx2Vxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. IMPORT LIBRARIES DAN KONFIGURASI"
      ],
      "metadata": {
        "id": "Ems8ft_DSCo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, dilakukan import semua library yang diperlukan untuk analisis data, pemodelan, dan visualisasi.\n",
        "\n",
        "Library yang Digunakan:\n",
        "- NumPy & Pandas: Manipulasi dan analisis data\n",
        "- Matplotlib: Visualisasi grafik dan chart\n",
        "- Scikit-learn: Implementasi algoritma machine learning (KNN, Decision Tree, Linear Regression)\n",
        "- Random: Untuk implementasi Genetic Algorithm dari nol\n"
      ],
      "metadata": {
        "id": "wu4uUrJUTHH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import r2_score as sklearn_r2\n",
        "from sklearn.metrics import mean_absolute_error as sklearn_mae\n",
        "\n",
        "# Untuk reproducibility - hasil akan sama setiap kali dijalankan\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "PXCUBjDiSFhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Load Data"
      ],
      "metadata": {
        "id": "AXa_TJkFSonL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, dataset dimuat ke dalam environment Python menggunakan library Pandas. Konfigurasi awal juga ditetapkan untuk menentukan variabel target yang akan diprediksi.\n"
      ],
      "metadata": {
        "id": "r-NzPjuKTHH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Konfigurasi path dan target\n",
        "DATA_PATH = '/content/house_price_regression_dataset.csv'\n",
        "TARGET_COL = 'House_Price'\n",
        "# Load dataset\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print('Dataset Shape:', df.shape)\n",
        "print(f'Jumlah Baris: {df.shape[0]:,}')\n",
        "print(f'Jumlah Kolom: {df.shape[1]}')\n",
        "print('\\nPreview Data:')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7gh9gT2q2rcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek apakah kolom target ada\n",
        "if TARGET_COL not in df.columns:\n",
        "    raise ValueError(f\"Kolom target '{TARGET_COL}' tidak ditemukan. Kolom yang ada: {list(df.columns)}\")\n",
        "\n",
        "# Hapus baris dengan target kosong\n",
        "before = len(df)\n",
        "df = df.dropna(subset=[TARGET_COL]).copy()\n",
        "after = len(df)\n",
        "print(f\"Baris dengan target kosong yang dihapus: {before - after}\")\n",
        "\n",
        "# Pastikan target bertipe numeric\n",
        "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
        "df = df.dropna(subset=[TARGET_COL]).copy()\n",
        "\n",
        "print(f'Shape setelah cleaning: {df.shape}')\n",
        "print('\\nStatistik Deskriptif:')\n",
        "df.describe(include='all').T.head(15)"
      ],
      "metadata": {
        "id": "a8OjSRwHSy3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna()"
      ],
      "metadata": {
        "id": "wD5tfzUeTvfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. EXPLORATORY DATA ANALYSIS (EDA)"
      ],
      "metadata": {
        "id": "UNTe12neS18i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Tujuan EDA\n",
        "\n",
        "Exploratory Data Analysis (EDA) merupakan tahapan krusial dalam proses data science yang bertujuan untuk memahami karakteristik data sebelum pemodelan. Melalui EDA, kita dapat mengidentifikasi pola, anomali, dan insight yang akan mempengaruhi keputusan dalam tahap preprocessing dan pemilihan model.\n",
        "\n",
        "Analisis yang Dilakukan:\n",
        "\n",
        "| No | Analisis | Tujuan |\n",
        "|:--:|:---------|:-------|\n",
        "| 1 | Missing Values | Mengidentifikasi data yang hilang yang dapat mempengaruhi kualitas model |\n",
        "| 2 | Duplikasi Data | Mendeteksi baris duplikat yang dapat menyebabkan bias |\n",
        "| 3 | Distribusi Target | Memahami sebaran harga rumah untuk menentukan transformasi yang diperlukan |\n",
        "| 4 | Korelasi Fitur | Mengidentifikasi fitur yang berpengaruh kuat terhadap target |\n",
        "| 5 | Outliers | Mendeteksi nilai ekstrem yang dapat mempengaruhi performa model |\n",
        "| 6 | Skewness | Mengukur kesimetrisan distribusi data |\n"
      ],
      "metadata": {
        "id": "b7MdADO7S8X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('--- Basic Info ---')\n",
        "display(df.info())\n",
        "\n",
        "print('\\n--- Dataset Shape ---')\n",
        "print(f'Rows: {len(df):,} | Columns: {len(df.columns)}')\n",
        "\n",
        "print('\\n--- Target Statistics ---')\n",
        "display(df[TARGET_COL].describe().to_frame())\n"
      ],
      "metadata": {
        "id": "gB1oR-6P3eMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretasi Informasi Dataset\n",
        "\n",
        "Dengan menggunakan fungsi dari library Python yang ada, kita dapat melihat gambaran umum data melalui statistik yang ada:\n",
        "\n",
        "Hasil Analisis:\n",
        "- Jumlah Data: 1.000 baris data (sampel rumah)\n",
        "- Jumlah Kolom: 8 kolom (7 fitur + 1 target)\n",
        "- Tipe Data: 6 kolom integer, 2 kolom float\n",
        "- Memory Usage: ~62.6 KB\n",
        "\n",
        "Statistik Deskriptif Target (House_Price):\n",
        "\n",
        "| Statistik | Nilai | Interpretasi |\n",
        "|-----------|-------|---------------|\n",
        "| Count | 1,000 | Semua data lengkap tanpa missing value |\n",
        "| Mean | \\$618,861 | Rata-rata harga rumah dalam dataset |\n",
        "| Std | \\$253,568 | Standar deviasi menunjukkan variasi harga yang cukup besar |\n",
        "| Min | \\$111,627 | Harga rumah terendah dalam dataset |\n",
        "| 25% | \\$401,648 | Kuartil pertama - 25% rumah di bawah harga ini |\n",
        "| 50% | \\$628,267 | Median - nilai tengah harga rumah |\n",
        "| 75% | \\$827,141 | Kuartil ketiga - 75% rumah di bawah harga ini |\n",
        "| Max | \\$1,108,237 | Harga rumah tertinggi dalam dataset |\n",
        "\n",
        "Rentang harga (range) mencapai hampir 10 kali lipat dari nilai minimum ke maksimum (\\$111K - \\$1.1M), menunjukkan keragaman tipe properti dalam dataset dari rumah sederhana hingga rumah mewah.\n"
      ],
      "metadata": {
        "id": "VYcQGKAaTHH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Cek Missing Value\n",
        "\n",
        "Pada tahap ini dilakukan pemeriksaan terhadap nilai yang hilang (missing value) dalam dataset. Missing value dapat muncul karena berbagai alasan seperti kesalahan input data, data tidak tersedia, atau masalah teknis saat pengumpulan data.\n",
        "\n",
        "Dampak Missing Value:\n",
        "- Mengurangi ukuran sampel jika baris dengan missing value dihapus\n",
        "- Dapat menyebabkan bias jika tidak ditangani dengan benar\n",
        "- Beberapa algoritma tidak dapat memproses data dengan missing value\n"
      ],
      "metadata": {
        "id": "VWeAccPjTHH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing = df.isna().sum().sort_values(ascending=False)\n",
        "missing_pct = (missing / len(df) * 100).round(2)\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing_Count': missing,\n",
        "    'Percentage': missing_pct\n",
        "})\n",
        "\n",
        "missing_df = missing_df[missing_df['Missing_Count'] > 0]\n",
        "\n",
        "if len(missing_df) > 0:\n",
        "    display(missing_df.head(20))\n",
        "\n",
        "    if len(missing_df) <= 20:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.bar(range(len(missing_df)), missing_df['Missing_Count'].values)\n",
        "        plt.xticks(range(len(missing_df)), missing_df.index, rotation=45, ha='right')\n",
        "        plt.ylabel('Missing Count')\n",
        "        plt.title('Missing Values per Feature')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print('No missing values')\n"
      ],
      "metadata": {
        "id": "2FOJn6NG3lmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dup_count = df.duplicated().sum()\n",
        "print(f'Duplicate rows: {dup_count} ({dup_count/len(df)*100:.2f}%)')\n",
        "\n",
        "invalid_target = (df[TARGET_COL] <= 0).sum()\n",
        "print(f'Invalid target values (<= 0): {invalid_target}')\n",
        "\n",
        "Q1 = df[TARGET_COL].quantile(0.25)\n",
        "Q3 = df[TARGET_COL].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "outliers = df[\n",
        "    (df[TARGET_COL] < Q1 - 1.5 * IQR) |\n",
        "    (df[TARGET_COL] > Q3 + 1.5 * IQR)\n",
        "]\n",
        "\n",
        "print(f'Outliers (IQR method): {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)')\n",
        "print(f'Target range: {df[TARGET_COL].min():,.0f} - {df[TARGET_COL].max():,.0f}')\n"
      ],
      "metadata": {
        "id": "vn6fzBwA3pDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Hasil Pemeriksaan Kualitas Data\n",
        "\n",
        "Berdasarkan hasil pemeriksaan kualitas data, dataset ini memiliki kondisi yang sangat baik:\n",
        "\n",
        "| Pemeriksaan | Hasil | Keterangan |\n",
        "|-------------|-------|------------|\n",
        "| Missing Values | 0 | Tidak ada data yang hilang pada semua kolom |\n",
        "| Duplicate Rows | 0 (0.00%) | Tidak ada baris yang terduplikasi |\n",
        "| Invalid Target | 0  | Tidak ada harga rumah dengan nilai ≤ 0 |\n",
        "| Outliers (IQR) | 0 (0.00%) | Tidak terdeteksi outlier ekstrem pada target |\n",
        "\n",
        "Kesimpulan: Dataset sudah bersih dan berkualitas tinggi. Tidak diperlukan penanganan khusus untuk missing values, duplikasi data, atau pembersihan outlier. Kondisi ini memungkinkan kita untuk langsung melanjutkan ke tahap analisis dan pemodelan tanpa preprocessing tambahan.\n"
      ],
      "metadata": {
        "id": "mJimg3TxTHH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.hist(df['House_Price'], bins=50, alpha=0.8)\n",
        "plt.title('Distribusi Harga Rumah', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Harga Rumah', fontsize=14)\n",
        "plt.ylabel('Frekuensi', fontsize=14)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "skew = df[TARGET_COL].skew()\n",
        "print(f'Target skewness: {skew:.2f}')\n"
      ],
      "metadata": {
        "id": "dR7r0-zriFQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(df['Square_Footage'], df['House_Price'], alpha=0.6)\n",
        "plt.title('Hubungan Luas Bangunan dengan Harga Rumah', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Luas Bangunan', fontsize=14)\n",
        "plt.ylabel('Harga Rumah', fontsize=14)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2T6EsLxoiPfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(df['Year_Built'], df['House_Price'], alpha=0.6)\n",
        "plt.title('Tahun Pembangunan vs Harga Rumah', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Tahun Dibangun', fontsize=14)\n",
        "plt.ylabel('Harga Rumah', fontsize=14)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g0hmpa1AiLpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "plt.boxplot(df[TARGET_COL].dropna(), vert=True)\n",
        "plt.title('Target Boxplot')\n",
        "plt.ylabel(TARGET_COL)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KyrXCS4P3rws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Analisis Distribusi Target (House_Price)\n",
        "\n",
        "Visualisasi distribusi target dilakukan untuk memahami karakteristik sebaran harga rumah dalam dataset. Analisis ini penting untuk menentukan apakah diperlukan transformasi data sebelum pemodelan.\n",
        "\n",
        "Hasil Analisis Histogram dan Boxplot:\n",
        "\n",
        "1. Bentuk Distribusi: Distribusi harga rumah relatif merata dan mendekati distribusi normal. Tidak terdapat kecenderungan ekstrem ke kiri (left-skewed) atau ke kanan (right-skewed).\n",
        "\n",
        "2. Skewness ≈ -0.06: Nilai skewness yang sangat mendekati 0 mengindikasikan distribusi yang hampir simetris sempurna. Dalam konteks statistik:\n",
        "   - Skewness = 0: Distribusi simetris sempurna\n",
        "   - Skewness antara -0.5 dan 0.5: Distribusi mendekati normal\n",
        "   - Skewness > 1 atau < -1: Distribusi sangat miring\n",
        "\n",
        "3. Tidak Ada Outlier: Boxplot menunjukkan bahwa seluruh data berada dalam rentang wajar (antara whisker). Tidak terdapat titik-titik di luar whisker yang mengindikasikan nilai ekstrem.\n",
        "\n",
        "4. Median vs Mean: Median (\\$628,267) sangat dekat dengan mean (\\$618,861), konfirmasi tambahan bahwa distribusi mendekati normal.\n",
        "\n",
        "Implikasi untuk Pemodelan:\n",
        "- Tidak diperlukan transformasi logaritmik atau Box-Cox karena distribusi sudah normal\n",
        "- Model dapat langsung dilatih dengan data asli\n",
        "- Interpretasi hasil prediksi lebih mudah karena satuan tetap dalam USD\n"
      ],
      "metadata": {
        "id": "yYJnf9AiTHH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
        "num_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
        "cat_cols = [c for c in feature_cols if c not in num_cols]\n",
        "\n",
        "print(f'Total features: {len(feature_cols)}')\n",
        "print(f'Numeric features: {len(num_cols)}')\n",
        "print(f'Categorical features: {len(cat_cols)}')\n"
      ],
      "metadata": {
        "id": "Pjfjug3n38AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(num_cols) > 0:\n",
        "    corr = df[num_cols + [TARGET_COL]].corr(numeric_only=True)[TARGET_COL].drop(TARGET_COL)\n",
        "    top_corr = corr.abs().sort_values(ascending=False).head(10)\n",
        "\n",
        "    corr_df = pd.DataFrame({\n",
        "        'Feature': top_corr.index,\n",
        "        'Abs_Correlation': top_corr.values,\n",
        "        'Correlation': corr[top_corr.index].values\n",
        "    })\n",
        "    display(corr_df)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.barh(top_corr.index, corr[top_corr.index].values)\n",
        "    plt.xlabel('Correlation with Target')\n",
        "    plt.title('Top 10 Feature Correlations')\n",
        "    plt.axvline(0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    top3 = top_corr.index[:3]\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    for i, col in enumerate(top3):\n",
        "        axes[i].scatter(df[col], df[TARGET_COL], alpha=0.5, s=20)\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel(TARGET_COL)\n",
        "        axes[i].set_title(f'{col} vs {TARGET_COL}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    skew_df = pd.DataFrame({'Skewness': df[num_cols].skew()})\n",
        "    display(skew_df.sort_values(by='Skewness', key=abs, ascending=False).head(10))\n",
        "\n",
        "\n",
        "if len(cat_cols) > 0:\n",
        "    cat_card_df = pd.DataFrame({\n",
        "        'Unique_Values': [df[col].nunique() for col in cat_cols]\n",
        "    }, index=cat_cols)\n",
        "\n",
        "    cat_card_df['Cardinality_Ratio'] = (cat_card_df['Unique_Values'] / len(df)) * 100\n",
        "    display(cat_card_df.sort_values('Unique_Values', ascending=False).head(15))\n",
        "\n",
        "    for col in cat_cols[:3]:\n",
        "        display(df[col].value_counts().head(10).to_frame('Count'))\n",
        "\n",
        "        if df[col].nunique() <= 10:\n",
        "            df.boxplot(column=TARGET_COL, by=col, figsize=(10, 6))\n",
        "            plt.suptitle('')\n",
        "            plt.title(f'{TARGET_COL} by {col}')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "Qzj3QS4z4BEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Analisis Korelasi Fitur\n",
        "\n",
        "Visualisasi matriks korelasi bertujuan untuk memetakan hubungan linear antar variabel dalam dataset. Melalui analisis ini, kita dapat mengidentifikasi fitur mana yang memiliki pengaruh paling kuat terhadap harga rumah.\n",
        "\n",
        "Hasil Analisis Korelasi dengan Target (House_Price):\n",
        "\n",
        "| Rank | Fitur | Korelasi | Kekuatan | Interpretasi |\n",
        "|:----:|:------|:--------:|:---------|:-------------|\n",
        "| 1 | Square_Footage | 0.991 | Sangat Kuat | Luas bangunan memiliki hubungan linear hampir sempurna dengan harga |\n",
        "| 2 | Lot_Size | 0.160 | Lemah | Luas tanah memiliki pengaruh positif namun lemah |\n",
        "| 3 | Garage_Size | 0.052 | Sangat Lemah | Ukuran garasi hampir tidak berpengaruh |\n",
        "| 4 | Year_Built | 0.052 | Sangat Lemah | Tahun pembangunan hampir tidak berpengaruh |\n",
        "| 5 | Num_Bedrooms | 0.015 | Negligible | Jumlah kamar tidur tidak berpengaruh signifikan |\n",
        "| 6 | Neighborhood_Quality | -0.008 | Negligible | Kualitas lingkungan tidak berpengaruh signifikan |\n",
        "| 7 | Num_Bathrooms | -0.002 | Negligible | Jumlah kamar mandi tidak berpengaruh signifikan |\n",
        "\n",
        "Temuan Kunci:\n",
        "\n",
        "Berdasarkan hasil analisis korelasi, terdapat satu fitur yang mendominasi yaitu `Square_Footage` dengan korelasi 0.991. Angka ini menunjukkan bahwa:\n",
        "- Sekitar 99% variasi harga rumah dapat dijelaskan oleh luas bangunan saja\n",
        "- Hubungan antara luas bangunan dan harga bersifat hampir perfectly linear\n",
        "- Fitur-fitur lain memiliki kontribusi yang minimal (korelasi < 0.2)\n",
        "\n",
        "Analisis Scatter Plot:\n",
        "- Square_Footage vs House_Price: Titik-titik data membentuk garis lurus dengan sangat sedikit penyimpangan, mengkonfirmasi hubungan linear yang kuat\n",
        "- Lot_Size vs House_Price: Pola tersebar acak tanpa tren yang jelas\n",
        "- Garage_Size vs House_Price: Data tersebar dalam kolom vertikal (karena nilai diskrit 0, 1, 2) tanpa korelasi dengan harga\n",
        "\n",
        "Implikasi untuk Pemodelan:\n",
        "\n",
        "1. Linear Regression diharapkan sangat efektif karena hubungan utama bersifat linear\n",
        "2. Feature selection oleh GA kemungkinan akan memilih Square_Footage sebagai fitur dominan\n",
        "3. Model kompleks (Decision Tree, KNN) mungkin tidak memberikan keunggulan signifikan dibandingkan Linear Regression karena pola data yang sederhana\n",
        "4. Fitur dengan korelasi mendekati 0 mungkin akan dibuang oleh GA karena tidak memberikan informasi tambahan yang berarti\n",
        "\n"
      ],
      "metadata": {
        "id": "anpiMjY0THIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. PREPROCESSING DATA"
      ],
      "metadata": {
        "id": "d3cu07kK4NmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Pemisahan Fitur dan Target\n",
        "\n",
        "Pada tahap ini, dilakukan persiapan data untuk proses pelatihan model. Langkah pertama adalah memisahkan variabel independen (fitur) dari variabel dependen (target).\n",
        "\n",
        "Pemisahan Data:\n",
        "- X (Fitur): Semua kolom kecuali House_Price — digunakan sebagai input untuk prediksi\n",
        "- y (Target): Kolom House_Price — nilai yang akan diprediksi oleh model\n",
        "\n",
        "## 5.2 Pembagian Data (Train/Validation/Test Split)\n",
        "\n",
        "Data dibagi menjadi 3 bagian dengan proporsi tertentu. Pembagian ini bertujuan untuk memastikan bahwa model yang dibangun dapat dievaluasi secara objektif dan tidak hanya bekerja baik pada data yang telah dilihat sebelumnya.\n",
        "\n",
        "| Dataset | Proporsi | Jumlah | Fungsi |\n",
        "|---------|:--------:|:------:|:-------|\n",
        "| Training | 70% | 700 sampel | Digunakan untuk melatih model. Model mempelajari pola dari data ini. |\n",
        "| Validation | 15% | 150 sampel | Digunakan untuk menghitung fitness GA. Membantu mencegah overfitting selama optimasi. |\n",
        "| Test | 15% | 150 sampel | Digunakan untuk evaluasi akhir. Data ini tidak pernah dilihat selama training atau optimasi. |\n",
        "\n",
        "Alasan Pembagian Tiga Bagian:\n",
        "\n",
        "1. Data Training: Digunakan sebagai data pembelajaran untuk model. Pada KNN, data training menjadi referensi untuk menghitung jarak. Pada Decision Tree, digunakan untuk membangun struktur pohon. Pada Linear Regression, digunakan untuk menghitung koefisien.\n",
        "\n",
        "2. Data Validation: Digunakan untuk menentukan parameter optimal melalui Genetic Algorithm. Dengan menggunakan data validation, pemilihan parameter dapat dilakukan tanpa melibatkan data testing sehingga evaluasi akhir tetap objektif. Penggunaan data validation membantu menghindari overfitting.\n",
        "\n",
        "3. Data Testing: Digunakan pada tahap akhir untuk mengukur performa sebenarnya dari model. Data ini tidak dilibatkan dalam proses training maupun optimasi, sehingga hasil evaluasi mencerminkan kemampuan model pada data yang benar-benar baru.\n",
        "\n",
        "Catatan:\n",
        "- `random_state=42` digunakan untuk reproducibility (hasil dapat direproduksi)\n",
        "- Tidak dilakukan scaling karena fitur sudah dalam skala yang relatif sebanding\n"
      ],
      "metadata": {
        "id": "6yzU9GXsTHIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur (x) dan target (y)\n",
        "X = df.drop(columns=[TARGET_COL])\n",
        "y = df[TARGET_COL]\n",
        "\n",
        "# Split data : train(70%), validation(15%), test(15%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "X_train_enc = X_train\n",
        "X_val_enc = X_val\n",
        "X_test_enc = X_test\n",
        "\n",
        "group_names = list(X.columns)\n",
        "group_to_encoded_cols = {col: [col] for col in group_names}\n",
        "\n",
        "print('=== DATA SPLIT ===')\n",
        "print(f'Training set   : {X_train.shape[0]:,} samples ({X_train.shape[0]/len(df)*100:.1f}%)')\n",
        "print(f'Validation set : {X_val.shape[0]:,} samples ({X_val.shape[0]/len(df)*100:.1f}%)')\n",
        "print(f'Test set       : {X_test.shape[0]:,} samples ({X_test.shape[0]/len(df)*100:.1f}%)')\n",
        "print(f'\\nJumlah fitur untuk GA: {len(group_names)}')\n",
        "print(f'Fitur: {group_names}')\n"
      ],
      "metadata": {
        "id": "j7Eb4TOVHL7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. IMPLEMENTASI GENETIC ALGORITHM"
      ],
      "metadata": {
        "id": "uD2hTHTQH_kW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Konsep Genetic Algorithm\n",
        "\n",
        "Genetic Algorithm (GA) adalah metode optimasi yang terinspirasi dari proses evolusi biologis. GA digunakan dalam penelitian ini untuk dua tujuan utama:\n",
        "\n",
        "1. Feature Selection: Memilih subset fitur terbaik dari 7 fitur yang tersedia\n",
        "2. Hyperparameter Tuning: Mencari kombinasi parameter optimal untuk setiap model\n",
        "\n",
        "### Representasi Kromosom\n",
        "\n",
        "Setiap individu (solusi kandidat) direpresentasikan sebagai array yang terdiri dari dua bagian:\n",
        "\n",
        "```\n",
        "Kromosom = [bit_1, bit_2, ..., bit_n, int_1, int_2, ...]\n",
        "            ├────── Bit Mask ──────┤ ├── Integer Genes ──┤\n",
        "            (Feature Selection)      (Hyperparameters)\n",
        "```\n",
        "\n",
        "Contoh untuk KNN (7 fitur):\n",
        "```\n",
        "[1, 0, 1, 1, 0, 1, 0,  |  7, 1, 2]\n",
        " ↑  ↑  ↑  ↑  ↑  ↑  ↑      ↑  ↑  ↑\n",
        " f1 f2 f3 f4 f5 f6 f7     k  w  p\n",
        "\n",
        "Artinya:\n",
        "- Fitur 1, 3, 4, 6 digunakan (bit=1)\n",
        "- Fitur 2, 5, 7 tidak digunakan (bit=0)\n",
        "- k = 7 neighbors\n",
        "- w = 1 → weights='distance'\n",
        "- p = 2 → Euclidean distance\n",
        "```\n",
        "\n",
        "### Komponen dan Operator GA\n",
        "\n",
        "| Komponen | Metode | Parameter | Penjelasan Detail |\n",
        "|----------|--------|-----------|-------------------|\n",
        "| Inisialisasi | Random | prob=0.6 | Setiap bit punya 60% kemungkinan bernilai 1, sehingga rata-rata 60% fitur terpilih di awal |\n",
        "| Fitness Function | RMSE Validation | - | Mengukur error prediksi pada validation set. Semakin kecil RMSE, semakin baik solusi |\n",
        "| Seleksi | Tournament | k=3 | Pilih 3 individu random, ambil yang fitness terbaik sebagai parent |\n",
        "| Crossover | Uniform | prob=0.8 | 80% kemungkinan crossover terjadi. Setiap gen punya 50% chance ditukar antara 2 parent |\n",
        "| Mutasi Bit | Flip | prob=0.03 | 3% kemungkinan setiap bit di-flip (0→1 atau 1→0) |\n",
        "| Mutasi Integer | Resample | prob=0.25 | 25% kemungkinan setiap integer gene di-random ulang dalam range valid |\n",
        "| Elitisme | Top-N | N=1 | 1 individu terbaik langsung masuk ke generasi berikutnya tanpa modifikasi |\n",
        "\n",
        "### Alur Proses Evolusi\n",
        "\n",
        "\n",
        "1. Inisialisasi\n",
        "*   Buat 30 individu dengan gen random\n",
        "*   Setiap individu = kombinasi fitur + hyperparameter\n",
        "2. Evaluasi Fitness Awal\n",
        "*   Train model dengan konfigurasi dari setiap kromosom\n",
        "*   Hitung RMSE pada validation set sebagai fitness\n",
        "3. Loop Selama 15 Generasi:\n",
        "*   Elitisme: Simpan 1 individu terbaik\n",
        "*   Seleksi: Pilih parent dengan tournament selection\n",
        "*   Crossover: Gabungkan gen dari 2 parent\n",
        "*   Mutasi: Perubahan random untuk eksplorasi\n",
        "*   Evaluasi: Hitung fitness generasi baru\n",
        "*   Update Best: Simpan jika ada yang lebih baik\n",
        "4. Return Solusi Terbaik\n",
        "*   Kromosom dengan RMSE validation terendah\n",
        "\n",
        "\n",
        "## 6.2 Parameter GA yang Digunakan\n",
        "\n",
        "| Parameter | Nilai | Alasan Pemilihan |\n",
        "|-----------|:-----:|------------------|\n",
        "| `pop_size` | 30 | Cukup besar untuk menjaga diversity genetik, namun tidak terlalu besar sehingga komputasi tetap efisien |\n",
        "| `n_gen` | 15 | Trade-off antara waktu konvergensi dan waktu komputasi. 15 generasi biasanya cukup untuk konvergensi |\n",
        "| `tourn_k` | 3 | Selection pressure sedang. k=3 memberikan keseimbangan antara eksploitasi dan eksplorasi |\n",
        "| `cx_prob` | 0.80 | Crossover rate tinggi untuk mendorong pertukaran informasi antar individu |\n",
        "| `bit_mut_prob` | 0.03 | Mutasi rendah untuk feature selection agar tidak terlalu banyak fitur berubah |\n",
        "| `int_mut_prob` | 0.25 | Lebih tinggi karena jumlah integer gene sedikit dan perlu eksplorasi lebih banyak |\n",
        "| `elite` | 1 | Menjamin solusi terbaik tidak pernah hilang dari populasi |\n",
        "\n",
        "## 6.3 Implementasi GA\n",
        "\n",
        "Berikut adalah implementasi Genetic Algorithm yang dibuat dari nol tanpa menggunakan library eksternal:\n"
      ],
      "metadata": {
        "id": "4q50U0vVTHID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "\n",
        "def decode_feature_mask(mask_bits, group_names, group_to_encoded_cols):\n",
        "    selected_groups = [g for bit, g in zip(mask_bits, group_names) if int(bit) == 1]\n",
        "    cols = []\n",
        "    for g in selected_groups:\n",
        "        cols.extend(group_to_encoded_cols.get(g, []))\n",
        "    return selected_groups, list(dict.fromkeys(cols))\n",
        "\n",
        "\n",
        "def _ensure_not_all_zero(bits):\n",
        "    if bits.sum() == 0:\n",
        "        bits[np.random.randint(0, len(bits))] = 1\n",
        "    return bits\n",
        "\n",
        "\n",
        "def init_population(pop_size, n_bits, int_genes):\n",
        "    pop = []\n",
        "    for _ in range(pop_size):\n",
        "        bits = (np.random.rand(n_bits) < 0.6).astype(int)\n",
        "        bits = _ensure_not_all_zero(bits)\n",
        "        ints = [np.random.randint(lo, hi + 1) for lo, hi in int_genes]\n",
        "        pop.append(np.concatenate([bits, ints]))\n",
        "    return np.array(pop, dtype=int)\n",
        "\n",
        "\n",
        "def tournament_select(pop, fitness, k=3):\n",
        "    idxs = np.random.randint(0, len(pop), size=k)\n",
        "    best = idxs[np.argmin(fitness[idxs])]\n",
        "    return pop[best].copy()\n",
        "\n",
        "\n",
        "def uniform_crossover(p1, p2):\n",
        "    mask = np.random.rand(len(p1)) < 0.5\n",
        "    c1, c2 = p1.copy(), p2.copy()\n",
        "    c1[mask] = p2[mask]\n",
        "    c2[mask] = p1[mask]\n",
        "    return c1, c2\n",
        "\n",
        "\n",
        "def mutate(ch, n_bits, int_genes, bit_mut_prob=0.03, int_mut_prob=0.25):\n",
        "    ch = ch.copy()\n",
        "\n",
        "    for i in range(n_bits):\n",
        "        if np.random.rand() < bit_mut_prob:\n",
        "            ch[i] = 1 - ch[i]\n",
        "    ch[:n_bits] = _ensure_not_all_zero(ch[:n_bits])\n",
        "\n",
        "    offset = n_bits\n",
        "    for j, (lo, hi) in enumerate(int_genes):\n",
        "        if np.random.rand() < int_mut_prob:\n",
        "            ch[offset + j] = np.random.randint(lo, hi + 1)\n",
        "\n",
        "    return ch\n",
        "\n",
        "\n",
        "def run_ga(\n",
        "    eval_fn,\n",
        "    n_bits,\n",
        "    int_genes,\n",
        "    pop_size=30,\n",
        "    n_gen=15,\n",
        "    tourn_k=3,\n",
        "    cx_prob=0.80,\n",
        "    bit_mut_prob=0.03,\n",
        "    int_mut_prob=0.25,\n",
        "    elite=1,\n",
        "    verbose=True,\n",
        "):\n",
        "    pop = init_population(pop_size, n_bits, int_genes)\n",
        "    fitness = np.array([eval_fn(ch) for ch in pop])\n",
        "\n",
        "    best_idx = np.argmin(fitness)\n",
        "    best_fit = fitness[best_idx]\n",
        "    best_ch = pop[best_idx].copy()\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Gen 0 | Best RMSE: {best_fit:.2f}')\n",
        "\n",
        "    for gen in range(1, n_gen + 1):\n",
        "        elite_idxs = np.argsort(fitness)[:elite]\n",
        "        new_pop = [pop[i].copy() for i in elite_idxs]\n",
        "\n",
        "        while len(new_pop) < pop_size:\n",
        "            p1 = tournament_select(pop, fitness, tourn_k)\n",
        "            p2 = tournament_select(pop, fitness, tourn_k)\n",
        "\n",
        "            if np.random.rand() < cx_prob:\n",
        "                c1, c2 = uniform_crossover(p1, p2)\n",
        "            else:\n",
        "                c1, c2 = p1.copy(), p2.copy()\n",
        "\n",
        "            new_pop.append(mutate(c1, n_bits, int_genes, bit_mut_prob, int_mut_prob))\n",
        "            if len(new_pop) < pop_size:\n",
        "                new_pop.append(mutate(c2, n_bits, int_genes, bit_mut_prob, int_mut_prob))\n",
        "\n",
        "        pop = np.array(new_pop, dtype=int)\n",
        "        fitness = np.array([eval_fn(ch) for ch in pop])\n",
        "\n",
        "        gen_best_idx = np.argmin(fitness)\n",
        "        gen_best_fit = fitness[gen_best_idx]\n",
        "\n",
        "        if gen_best_fit < best_fit:\n",
        "            best_fit = gen_best_fit\n",
        "            best_ch = pop[gen_best_idx].copy()\n",
        "\n",
        "        if verbose:\n",
        "            print(f'Gen {gen} | Best RMSE: {best_fit:.2f}')\n",
        "\n",
        "    return best_ch, best_fit\n"
      ],
      "metadata": {
        "id": "ChH3KK-nIKSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. IMPLEMENTASI MODEL\n",
        "\n",
        "## 7.1 Model 1: K-Nearest Neighbors (KNN) + GA"
      ],
      "metadata": {
        "id": "8wJAODexIc4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Konfigurasi KNN untuk Optimasi GA\n",
        "\n",
        "Pada model KNN, GA akan mengoptimasi feature selection dan 3 hyperparameter berikut:\n",
        "\n",
        "| Parameter | Range | Penjelasan |\n",
        "|-----------|:-----:|------------|\n",
        "| n_neighbors (k) | 1-50 | Jumlah tetangga terdekat. k kecil → model sensitif, k besar → model lebih smooth |\n",
        "| weights | 0 atau 1 | 0='uniform' (semua tetangga sama penting), 1='distance' (tetangga dekat lebih berpengaruh) |\n",
        "| p | 1 atau 2 | Metrik jarak. 1=Manhattan, 2=Euclidean |\n",
        "\n",
        "Kode berikut menjalankan GA untuk menemukan kombinasi optimal:\n"
      ],
      "metadata": {
        "id": "CZJfUuEOTHID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_bits = len(group_names)\n",
        "\n",
        "int_genes_knn = [\n",
        "    (1, 50),\n",
        "    (0, 1),\n",
        "    (1, 2),\n",
        "]\n",
        "\n",
        "def eval_knn(chrom):\n",
        "    bits = chrom[:n_bits].astype(int)\n",
        "    k, w, p = chrom[n_bits:].astype(int)\n",
        "\n",
        "    if bits.sum() == 0:\n",
        "        return 1e9\n",
        "\n",
        "    _, cols = decode_feature_mask(bits, group_names, group_to_encoded_cols)\n",
        "    if len(cols) == 0:\n",
        "        return 1e9\n",
        "\n",
        "    weights = 'distance' if w == 1 else 'uniform'\n",
        "    model = KNeighborsRegressor(n_neighbors=int(k), weights=weights, p=int(p))\n",
        "    model.fit(X_train_enc[cols], y_train)\n",
        "    pred = model.predict(X_val_enc[cols])\n",
        "    return rmse(y_val, pred)\n",
        "\n",
        "\n",
        "best_knn_ch, best_knn_rmse = run_ga(\n",
        "    eval_fn=eval_knn,\n",
        "    n_bits=n_bits,\n",
        "    int_genes=int_genes_knn,\n",
        "    pop_size=30,\n",
        "    n_gen=15,\n",
        "    cx_prob=0.8,\n",
        "    bit_mut_prob=0.03,\n",
        "    int_mut_prob=0.25,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "bits = best_knn_ch[:n_bits].astype(int)\n",
        "k, w, p = best_knn_ch[n_bits:].astype(int)\n",
        "\n",
        "selected_groups, selected_cols = decode_feature_mask(\n",
        "    bits, group_names, group_to_encoded_cols\n",
        ")\n",
        "\n",
        "weights = 'distance' if w == 1 else 'uniform'\n",
        "\n",
        "print('\\nBest KNN configuration')\n",
        "print('Selected features:', len(selected_groups))\n",
        "print('k:', int(k), 'weights:', weights, 'p:', int(p))\n",
        "\n",
        "\n",
        "knn_best = KNeighborsRegressor(n_neighbors=int(k), weights=weights, p=int(p))\n",
        "knn_best.fit(X_train_enc[selected_cols], y_train)\n",
        "\n",
        "knn_train_pred = knn_best.predict(X_train_enc[selected_cols])\n",
        "knn_val_pred = knn_best.predict(X_val_enc[selected_cols])\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "knn_train_rmse = rmse(y_train, knn_train_pred)\n",
        "knn_train_mae = mean_absolute_error(y_train, knn_train_pred)\n",
        "knn_train_r2 = r2_score(y_train, knn_train_pred)\n",
        "\n",
        "knn_val_rmse = rmse(y_val, knn_val_pred)\n",
        "knn_val_mae = mean_absolute_error(y_val, knn_val_pred)\n",
        "knn_val_r2 = r2_score(y_val, knn_val_pred)\n",
        "\n",
        "print('\\nTrain metrics')\n",
        "print(f'RMSE: {knn_train_rmse:.2f}')\n",
        "print(f'MAE : {knn_train_mae:.2f}')\n",
        "print(f'R2  : {knn_train_r2:.4f}')\n",
        "\n",
        "print('\\nValidation metrics')\n",
        "print(f'RMSE: {knn_val_rmse:.2f}')\n",
        "print(f'MAE : {knn_val_mae:.2f}')\n",
        "print(f'R2  : {knn_val_r2:.4f}')\n",
        "\n",
        "\n",
        "X_trainval = pd.concat([X_train_enc, X_val_enc])\n",
        "y_trainval = pd.concat([y_train, y_val])\n",
        "\n",
        "knn_final = KNeighborsRegressor(n_neighbors=int(k), weights=weights, p=int(p))\n",
        "knn_final.fit(X_trainval[selected_cols], y_trainval)\n",
        "\n",
        "knn_test_pred = knn_final.predict(X_test_enc[selected_cols])\n",
        "\n",
        "knn_test_rmse = rmse(y_test, knn_test_pred)\n",
        "knn_test_mae = mean_absolute_error(y_test, knn_test_pred)\n",
        "knn_test_r2 = r2_score(y_test, knn_test_pred)\n",
        "\n",
        "print('\\nTest metrics')\n",
        "print(f'RMSE: {knn_test_rmse:.2f}')\n",
        "print(f'MAE : {knn_test_mae:.2f}')\n",
        "print(f'R2  : {knn_test_r2:.4f}')\n"
      ],
      "metadata": {
        "id": "RG0S1mgmIhqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretasi Hasil KNN + GA\n",
        "\n",
        "Berdasarkan hasil eksekusi Genetic Algorithm di atas, diperoleh parameter optimal untuk model KNN.\n",
        "\n",
        "Parameter Optimal yang Ditemukan:\n",
        "- GA secara otomatis memilih fitur-fitur yang paling relevan\n",
        "- Nilai k, weights, dan p optimal ditentukan berdasarkan RMSE validation terendah\n",
        "\n",
        "NOTE: Fenomena Train RMSE = 0\n",
        "\n",
        "Jika hasil menunjukkan Train RMSE = 0 dan Train R² = 1.0, ini adalah perilaku normal untuk KNN dengan `weights='distance'`, bukan error atau bug.\n",
        "\n",
        "Penjelasan Fenomena:\n",
        "\n",
        "Ketika KNN dengan `weights='distance'` memprediksi data yang sudah ada di training set:\n",
        "\n",
        "1. Titik tersebut menjadi tetangga terdekat dirinya sendiri dengan jarak = 0\n",
        "2. Dengan pembobotan distance, bobot dihitung sebagai 1/jarak = 1/0 = ∞ (infinite)\n",
        "3. Bobot infinite membuat prediksi 100% ditentukan oleh titik itu sendiri\n",
        "4. Akibatnya, prediksi selalu sama persis dengan nilai asli → error = 0\n",
        "\n",
        "\n",
        "Kesimpulan:\n",
        "- Validation RMSE: Valid dan digunakan untuk fitness GA\n",
        "- Test RMSE: Valid untuk evaluasi performa sebenarnya\n",
        "- Train RMSE: Tidak bermakna untuk KNN dengan distance weighting, sebaiknya diabaikan\n",
        "\n",
        "Metrik yang harus diperhatikan untuk menilai performa KNN adalah Validation dan Test metrics.\n"
      ],
      "metadata": {
        "id": "EcQn9aK1THID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Model 2: Decision Tree + GA"
      ],
      "metadata": {
        "id": "Ic4S4DidI4-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Konfigurasi Decision Tree untuk Optimasi GA\n",
        "\n",
        "Pada model Decision Tree, GA akan mengoptimasi feature selection dan 4 hyperparameter berikut:\n",
        "\n",
        "| Parameter | Range | Penjelasan |\n",
        "|-----------|:-----:|------------|\n",
        "| max_depth | 0-30 | Kedalaman maksimum pohon. 0=unlimited. Terlalu dalam → overfitting |\n",
        "| min_samples_split | 2-20 | Minimum sampel untuk melakukan split. Lebih besar → pohon lebih sederhana |\n",
        "| min_samples_leaf | 1-10 | Minimum sampel di leaf node. Lebih besar → mencegah overfitting |\n",
        "| criterion | 0 atau 1 | 0='squared_error', 1='absolute_error' |\n",
        "\n",
        "Kode berikut menjalankan GA untuk menemukan kombinasi optimal:\n"
      ],
      "metadata": {
        "id": "HdCDsVzNTHID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_genes_dt = [\n",
        "    (0, 30),\n",
        "    (2, 20),\n",
        "    (1, 10),\n",
        "    (0, 1),\n",
        "]\n",
        "\n",
        "def eval_dt(chrom):\n",
        "    # Memisahkan bagian seleksi fitur dan parameter model\n",
        "    bits = chrom[:n_bits].astype(int)\n",
        "    max_depth, mss, msl, crit = chrom[n_bits:].astype(int)\n",
        "\n",
        "    # Jika tidak ada fitur yang dipilih, beri penalti\n",
        "    if bits.sum() == 0:\n",
        "        return 1e9\n",
        "\n",
        "    # Ambil kolom berdasarkan bit mask\n",
        "    _, cols = decode_feature_mask(bits, group_names, group_to_encoded_cols)\n",
        "    if len(cols) == 0:\n",
        "        return 1e9\n",
        "\n",
        "    # Konversi parameter GA ke format Decision Tree\n",
        "    depth = None if max_depth == 0 else int(max_depth)\n",
        "    criterion = 'absolute_error' if crit == 1 else 'squared_error'\n",
        "\n",
        "    # Latih model pada data training\n",
        "    model = DecisionTreeRegressor(\n",
        "        random_state=RANDOM_SEED,\n",
        "        max_depth=depth,\n",
        "        min_samples_split=int(mss),\n",
        "        min_samples_leaf=int(msl),\n",
        "        criterion=criterion,\n",
        "    )\n",
        "    model.fit(X_train_enc[cols], y_train)\n",
        "\n",
        "    # Evaluasi menggunakan data validasi\n",
        "    pred = model.predict(X_val_enc[cols])\n",
        "    return rmse(y_val, pred)\n",
        "\n",
        "\n",
        "# Menjalankan GA untuk mencari konfigurasi terbaik\n",
        "best_dt_ch, best_dt_rmse = run_ga(\n",
        "    eval_fn=eval_dt,\n",
        "    n_bits=n_bits,\n",
        "    int_genes=int_genes_dt,\n",
        "    pop_size=30,\n",
        "    n_gen=15,\n",
        "    cx_prob=0.8,\n",
        "    bit_mut_prob=0.03,\n",
        "    int_mut_prob=0.25,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Ekstraksi hasil terbaik\n",
        "bits = best_dt_ch[:n_bits].astype(int)\n",
        "max_depth, mss, msl, crit = best_dt_ch[n_bits:].astype(int)\n",
        "\n",
        "selected_groups, selected_cols = decode_feature_mask(\n",
        "    bits, group_names, group_to_encoded_cols\n",
        ")\n",
        "\n",
        "depth = None if max_depth == 0 else int(max_depth)\n",
        "criterion = 'absolute_error' if crit == 1 else 'squared_error'\n",
        "\n",
        "print('\\nBest Decision Tree configuration')\n",
        "print('Number of selected features:', len(selected_groups))\n",
        "print(\n",
        "    'max_depth:', depth,\n",
        "    '\\nmin_samples_split:', int(mss),\n",
        "    '\\nmin_samples_leaf:', int(msl),\n",
        "    '\\ncriterion:', criterion\n",
        ")\n",
        "\n",
        "# Melatih model terbaik pada data training\n",
        "dt_best = DecisionTreeRegressor(\n",
        "    random_state=RANDOM_SEED,\n",
        "    max_depth=depth,\n",
        "    min_samples_split=int(mss),\n",
        "    min_samples_leaf=int(msl),\n",
        "    criterion=criterion,\n",
        ")\n",
        "dt_best.fit(X_train_enc[selected_cols], y_train)\n",
        "\n",
        "# Prediksi data training dan validasi\n",
        "dt_train_pred = dt_best.predict(X_train_enc[selected_cols])\n",
        "dt_val_pred = dt_best.predict(X_val_enc[selected_cols])\n",
        "\n",
        "# Evaluasi performa\n",
        "dt_train_rmse = rmse(y_train, dt_train_pred)\n",
        "dt_train_mae = mean_absolute_error(y_train, dt_train_pred)\n",
        "dt_train_r2 = r2_score(y_train, dt_train_pred)\n",
        "\n",
        "dt_val_rmse = rmse(y_val, dt_val_pred)\n",
        "dt_val_mae = mean_absolute_error(y_val, dt_val_pred)\n",
        "dt_val_r2 = r2_score(y_val, dt_val_pred)\n",
        "\n",
        "print('\\nTraining results')\n",
        "print(f'RMSE: {dt_train_rmse:.2f}')\n",
        "print(f'MAE : {dt_train_mae:.2f}')\n",
        "print(f'R2  : {dt_train_r2:.4f}')\n",
        "\n",
        "print('\\nValidation results')\n",
        "print(f'RMSE: {dt_val_rmse:.2f}')\n",
        "print(f'MAE : {dt_val_mae:.2f}')\n",
        "print(f'R2  : {dt_val_r2:.4f}')\n",
        "\n",
        "# Pelatihan ulang menggunakan data train + validation\n",
        "X_trainval = pd.concat([X_train_enc, X_val_enc])\n",
        "y_trainval = pd.concat([y_train, y_val])\n",
        "\n",
        "dt_final = DecisionTreeRegressor(\n",
        "    random_state=RANDOM_SEED,\n",
        "    max_depth=depth,\n",
        "    min_samples_split=int(mss),\n",
        "    min_samples_leaf=int(msl),\n",
        "    criterion=criterion,\n",
        ")\n",
        "dt_final.fit(X_trainval[selected_cols], y_trainval)\n",
        "\n",
        "# Evaluasi pada data test\n",
        "dt_test_pred = dt_final.predict(X_test_enc[selected_cols])\n",
        "\n",
        "dt_test_rmse = rmse(y_test, dt_test_pred)\n",
        "dt_test_mae = mean_absolute_error(y_test, dt_test_pred)\n",
        "dt_test_r2 = r2_score(y_test, dt_test_pred)\n",
        "\n",
        "print('\\nTest results')\n",
        "print(f'RMSE: {dt_test_rmse:.2f}')\n",
        "print(f'MAE : {dt_test_mae:.2f}')\n",
        "print(f'R2  : {dt_test_r2:.4f}')\n"
      ],
      "metadata": {
        "id": "Z7r4zJyNI92s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretasi Hasil Decision Tree + GA\n",
        "\n",
        "Berdasarkan hasil eksekusi GA, diperoleh parameter optimal untuk model Decision Tree.\n",
        "\n",
        "Analisis Hyperparameter:\n",
        "\n",
        "1. max_depth: Kedalaman pohon yang optimal menunjukkan seberapa kompleks aturan keputusan yang diperlukan. Jika max_depth rendah, berarti pola dalam data cukup sederhana.\n",
        "\n",
        "2. min_samples_split & min_samples_leaf: Nilai yang lebih tinggi menghasilkan pohon yang lebih sederhana dan lebih resistant terhadap overfitting.\n",
        "\n",
        "3. criterion: Pilihan antara squared_error (default) atau absolute_error bergantung pada sensitivitas terhadap outlier yang diinginkan.\n",
        "\n",
        "Karakteristik Decision Tree:\n",
        "- Dapat menangkap hubungan non-linear\n",
        "- Mudah diinterpretasi (dapat divisualisasi sebagai pohon)\n",
        "- Rentan overfitting jika tidak dikontrol dengan baik\n",
        "\n"
      ],
      "metadata": {
        "id": "fvY30by2THID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 Model 3: Linear Regression + GA"
      ],
      "metadata": {
        "id": "dqX-SQekJ_Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Konfigurasi Linear Regression untuk Optimasi GA\n",
        "\n",
        "Linear Regression adalah model paling sederhana yang digunakan dalam penelitian ini. Karena tidak memiliki hyperparameter kompleks, GA hanya digunakan untuk feature selection.\n",
        "\n",
        "Karakteristik Linear Regression:\n",
        "- Mengasumsikan hubungan linear antara fitur dan target\n",
        "- Tidak memiliki hyperparameter untuk di-tune (kecuali regularization yang tidak digunakan di sini)\n",
        "- Cepat dalam training dan prediksi\n",
        "- Mudah diinterpretasi melalui koefisien\n",
        "\n",
        "Kode berikut menjalankan GA untuk memilih fitur optimal:\n"
      ],
      "metadata": {
        "id": "g9F9iW5JTHID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_genes_lr = []\n",
        "def eval_lr(chrom):\n",
        "    # Ambil bit seleksi fitur\n",
        "    bits = chrom[:n_bits].astype(int)\n",
        "\n",
        "    # Kondisi tidak valid jika tidak ada fitur terpilih\n",
        "    if bits.sum() == 0:\n",
        "        return 1e9\n",
        "\n",
        "    # Tentukan kolom yang digunakan\n",
        "    _, cols = decode_feature_mask(bits, group_names, group_to_encoded_cols)\n",
        "    if len(cols) == 0:\n",
        "        return 1e9\n",
        "\n",
        "    # Latih model Linear Regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_enc[cols], y_train)\n",
        "\n",
        "    # Evaluasi pada data validasi\n",
        "    pred = model.predict(X_val_enc[cols])\n",
        "    return rmse(y_val, pred)\n",
        "\n",
        "\n",
        "# Proses optimasi menggunakan Genetic Algorithm\n",
        "best_lr_ch, best_lr_rmse = run_ga(\n",
        "    eval_fn=eval_lr,\n",
        "    n_bits=n_bits,\n",
        "    int_genes=int_genes_lr,\n",
        "    pop_size=30,\n",
        "    n_gen=15,\n",
        "    cx_prob=0.8,\n",
        "    bit_mut_prob=0.03,\n",
        "    int_mut_prob=0.0,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Ekstraksi fitur terbaik\n",
        "bits = best_lr_ch[:n_bits].astype(int)\n",
        "selected_groups, selected_cols = decode_feature_mask(\n",
        "    bits, group_names, group_to_encoded_cols\n",
        ")\n",
        "\n",
        "print('\\nBest Linear Regression configuration')\n",
        "print('Number of selected features:', len(selected_groups))\n",
        "\n",
        "\n",
        "# Pelatihan model menggunakan fitur terpilih\n",
        "lr_best = LinearRegression()\n",
        "lr_best.fit(X_train_enc[selected_cols], y_train)\n",
        "\n",
        "# Prediksi data training dan validasi\n",
        "lr_train_pred = lr_best.predict(X_train_enc[selected_cols])\n",
        "lr_val_pred = lr_best.predict(X_val_enc[selected_cols])\n",
        "\n",
        "# Evaluasi performa\n",
        "lr_train_rmse = rmse(y_train, lr_train_pred)\n",
        "lr_train_mae = mean_absolute_error(y_train, lr_train_pred)\n",
        "lr_train_r2 = r2_score(y_train, lr_train_pred)\n",
        "\n",
        "lr_val_rmse = rmse(y_val, lr_val_pred)\n",
        "lr_val_mae = mean_absolute_error(y_val, lr_val_pred)\n",
        "lr_val_r2 = r2_score(y_val, lr_val_pred)\n",
        "\n",
        "print('\\nTraining results')\n",
        "print(f'RMSE: {lr_train_rmse:.2f}')\n",
        "print(f'MAE : {lr_train_mae:.2f}')\n",
        "print(f'R2  : {lr_train_r2:.4f}')\n",
        "\n",
        "print('\\nValidation results')\n",
        "print(f'RMSE: {lr_val_rmse:.2f}')\n",
        "print(f'MAE : {lr_val_mae:.2f}')\n",
        "print(f'R2  : {lr_val_r2:.4f}')\n",
        "\n",
        "\n",
        "# Pelatihan ulang menggunakan gabungan data training dan validasi\n",
        "X_trainval = pd.concat([X_train_enc, X_val_enc])\n",
        "y_trainval = pd.concat([y_train, y_val])\n",
        "\n",
        "lr_final = LinearRegression()\n",
        "lr_final.fit(X_trainval[selected_cols], y_trainval)\n",
        "\n",
        "# Evaluasi pada data test\n",
        "lr_test_pred = lr_final.predict(X_test_enc[selected_cols])\n",
        "\n",
        "lr_test_rmse = rmse(y_test, lr_test_pred)\n",
        "lr_test_mae = mean_absolute_error(y_test, lr_test_pred)\n",
        "lr_test_r2 = r2_score(y_test, lr_test_pred)\n",
        "\n",
        "print('\\nTest results')\n",
        "print(f'RMSE: {lr_test_rmse:.2f}')\n",
        "print(f'MAE : {lr_test_mae:.2f}')\n",
        "print(f'R2  : {lr_test_r2:.4f}')\n"
      ],
      "metadata": {
        "id": "ggSN4iUzJ_Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretasi Hasil Linear Regression + GA\n",
        "\n",
        "Berdasarkan hasil EDA sebelumnya, variabel `Square_Footage` memiliki korelasi 0.991 dengan House_Price. Ini menunjukkan hubungan yang hampir perfectly linear antara luas bangunan dan harga rumah.\n",
        "\n",
        "Mengapa Linear Regression Diharapkan Sangat Baik?\n",
        "\n",
        "1. Asumsi Linearitas Terpenuhi: Scatter plot Square_Footage vs House_Price membentuk garis lurus dengan sangat sedikit penyimpangan.\n",
        "\n",
        "2. Kesederhanaan adalah Kelebihan: Dalam kasus dimana hubungan memang linear, model yang lebih kompleks tidak akan memberikan keuntungan dan malah berisiko overfitting.\n",
        "\n",
        "3. Feature Selection Efektif: GA kemungkinan akan memilih Square_Footage sebagai fitur utama (atau bahkan satu-satunya) karena fitur lain tidak berkontribusi signifikan.\n",
        "\n",
        "Formula Prediksi:\n",
        "```\n",
        "House_Price = β₀ + β₁×Square_Footage + β₂×Fitur₂ + ... + βₙ×Fiturₙ\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "KVgsNhOPTHID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. HASIL DAN ANALISIS"
      ],
      "metadata": {
        "id": "591jWigmLbI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1 Metrik Evaluasi\n",
        "\n",
        "Tahap terakhir dalam alur penelitian ini adalah Evaluasi Performa Model. Setelah model final terbentuk dengan parameter optimal dari GA, dilakukan pengujian menyeluruh untuk mengukur kemampuan generalisasi model.\n",
        "\n",
        "Metrik yang Digunakan:\n",
        "\n",
        "| Metrik | Formula | Interpretasi | Semakin Baik Jika |\n",
        "|--------|---------|--------------|-------------------|\n",
        "| RMSE | $\\sqrt{\\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2}$ | Root Mean Squared Error - error dalam satuan asli (USD) | Semakin kecil |\n",
        "| MAE | $\\frac{1}{n}\\sum|y_i - \\hat{y}_i|$ | Mean Absolute Error - rata-rata error absolut | Semakin kecil |\n",
        "| R² | $1 - \\frac{SS_{res}}{SS_{tot}}$ | Proporsi variansi yang dijelaskan oleh model (0-1) | Mendekati 1 |\n",
        "| MAPE | $\\frac{100}{n}\\sum|\\frac{y_i - \\hat{y}_i}{y_i}|$ | Mean Absolute Percentage Error - error dalam % | Semakin kecil |\n",
        "\n",
        "Interpretasi Metrik:\n",
        "\n",
        "1. RMSE (Root Mean Squared Error):\n",
        "   - Memberikan penalti lebih besar untuk error yang besar\n",
        "   - Dalam satuan yang sama dengan target (USD)\n",
        "   - RMSE = $10,000 (berarti rata-rata error prediksi sekitar 10.000 dollar)\n",
        "\n",
        "2. MAE (Mean Absolute Error):\n",
        "   - Lebih robust terhadap outlier dibanding RMSE\n",
        "   - Interpretasi langsung: rata-rata kesalahan prediksi\n",
        "\n",
        "3. R² (Coefficient of Determination):\n",
        "   - R² = 1.0: Model menjelaskan 100% variasi data (perfect)\n",
        "   - R² = 0.9: Model menjelaskan 90% variasi data (sangat baik)\n",
        "   - R² = 0.0: Model tidak lebih baik dari prediksi menggunakan mean\n",
        "\n",
        "4. MAPE (Mean Absolute Percentage Error):\n",
        "   - Mudah dikomunikasikan: \"Model memprediksi dengan error rata-rata X%\"\n",
        "   - MAPE < 10% umumnya dianggap akurat\n",
        "\n",
        "Blok kode berikut menghitung metrik evaluasi pada tiga subset data:\n"
      ],
      "metadata": {
        "id": "ZkWv4Ke6THIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2"
      ],
      "metadata": {
        "id": "kor1cwTWde5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Hitung MAPE pada data test\n",
        "knn_test_mape = mape(y_test, knn_test_pred)\n",
        "dt_test_mape = mape(y_test, dt_test_pred)\n",
        "lr_test_mape = mape(y_test, lr_test_pred)\n",
        "\n",
        "\n",
        "# Tabel perbandingan performa model\n",
        "results = pd.DataFrame([\n",
        "    {\n",
        "        'Model': 'KNN + GA',\n",
        "        'Train_RMSE': knn_train_rmse,\n",
        "        'Train_MAE': knn_train_mae,\n",
        "        'Train_R2': knn_train_r2,\n",
        "        'Val_RMSE': knn_val_rmse,\n",
        "        'Val_MAE': knn_val_mae,\n",
        "        'Val_R2': knn_val_r2,\n",
        "        'Test_RMSE': knn_test_rmse,\n",
        "        'Test_MAE': knn_test_mae,\n",
        "        'Test_MAPE (%)': knn_test_mape,\n",
        "        'Test_R2': knn_test_r2,\n",
        "    },\n",
        "    {\n",
        "        'Model': 'Decision Tree + GA',\n",
        "        'Train_RMSE': dt_train_rmse,\n",
        "        'Train_MAE': dt_train_mae,\n",
        "        'Train_R2': dt_train_r2,\n",
        "        'Val_RMSE': dt_val_rmse,\n",
        "        'Val_MAE': dt_val_mae,\n",
        "        'Val_R2': dt_val_r2,\n",
        "        'Test_RMSE': dt_test_rmse,\n",
        "        'Test_MAE': dt_test_mae,\n",
        "        'Test_MAPE (%)': dt_test_mape,\n",
        "        'Test_R2': dt_test_r2,\n",
        "    },\n",
        "    {\n",
        "        'Model': 'Linear Regression + GA',\n",
        "        'Train_RMSE': lr_train_rmse,\n",
        "        'Train_MAE': lr_train_mae,\n",
        "        'Train_R2': lr_train_r2,\n",
        "        'Val_RMSE': lr_val_rmse,\n",
        "        'Val_MAE': lr_val_mae,\n",
        "        'Val_R2': lr_val_r2,\n",
        "        'Test_RMSE': lr_test_rmse,\n",
        "        'Test_MAE': lr_test_mae,\n",
        "        'Test_MAPE (%)': lr_test_mape,\n",
        "        'Test_R2': lr_test_r2,\n",
        "    },\n",
        "]).sort_values('Test_RMSE')\n",
        "\n",
        "print('Model performance comparison')\n",
        "display(results)\n",
        "\n",
        "print('\\nOverfitting Analisis')\n",
        "for _, row in results.iterrows():\n",
        "    model_name = row['Model']\n",
        "    train_rmse_val = row['Train_RMSE']\n",
        "    val_rmse_val = row['Val_RMSE']\n",
        "    test_rmse_val = row['Test_RMSE']\n",
        "\n",
        "    selisih = train_rmse_val - val_rmse_val\n",
        "\n",
        "    print(f\"\\n{model_name}\")\n",
        "    print(f\"Train RMSE : {train_rmse_val:,.2f}\")\n",
        "    print(f\"Val RMSE   : {val_rmse_val:,.2f}\")\n",
        "    print(f\"Test RMSE  : {test_rmse_val:,.2f}\")\n",
        "\n",
        "    if train_rmse_val < val_rmse_val - 5000:\n",
        "        print(f\"Indikasi: overfitting (selisih {selisih:,.2f})\")\n",
        "    elif abs(selisih) < 2000:\n",
        "        print(f\"Indikasi: model stabil (selisih {selisih:,.2f})\")\n",
        "    else:\n",
        "        print(f\"Selisih Train–Validation: {selisih:,.2f}\")\n"
      ],
      "metadata": {
        "id": "xBJNoK6dLvps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.3 Visualisasi Perbandingan Model"
      ],
      "metadata": {
        "id": "mSPwhKPDMaCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisasi berikut bertujuan untuk mempermudah interpretasi hasil perbandingan model secara grafis. Melalui visualisasi, perbedaan performa antar model dapat terlihat dengan lebih jelas dan intuitif.\n"
      ],
      "metadata": {
        "id": "X96VxPo9THIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['Linear Regression\\n+ GA', 'Decision Tree\\n+ GA', 'KNN\\n+ GA']\n",
        "\n",
        "# Use the already calculated values from your comparison table\n",
        "train_rmse = [lr_train_rmse, dt_train_rmse, knn_train_rmse]\n",
        "val_rmse = [lr_val_rmse, dt_val_rmse, knn_val_rmse]\n",
        "test_rmse = [lr_test_rmse, dt_test_rmse, knn_test_rmse]\n",
        "\n",
        "train_mae = [lr_train_mae, dt_train_mae, knn_train_mae]\n",
        "val_mae = [lr_val_mae, dt_val_mae, knn_val_mae]\n",
        "test_mae = [sklearn_mae(y_test, lr_test_pred),\n",
        "            sklearn_mae(y_test, dt_test_pred),\n",
        "            sklearn_mae(y_test, knn_test_pred)]\n",
        "\n",
        "train_r2 = [lr_train_r2, dt_train_r2, knn_train_r2]\n",
        "val_r2 = [lr_val_r2, dt_val_r2, knn_val_r2]\n",
        "test_r2 = [lr_test_r2, dt_test_r2, knn_test_r2]\n",
        "\n",
        "test_mape = [mape(y_test, lr_test_pred),\n",
        "             mape(y_test, dt_test_pred),\n",
        "             mape(y_test, knn_test_pred)]\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']  # Green, Blue, Red\n",
        "\n",
        "# Create figure with subplots\n",
        "fig = plt.figure(figsize=(18, 12))"
      ],
      "metadata": {
        "id": "xnHvGB8PMZor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "x = np.arange(len(models))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax1.bar(x - width, train_rmse, width, label='Train', alpha=0.85)\n",
        "bars2 = ax1.bar(x, val_rmse, width, label='Validasi', alpha=0.85)\n",
        "bars3 = ax1.bar(x + width, test_rmse, width, label='Test', alpha=0.85)\n",
        "\n",
        "ax1.set_title('Perbandingan RMSE', fontsize=15, fontweight='bold')\n",
        "ax1.set_xlabel('Model', fontsize=12)\n",
        "ax1.set_ylabel('RMSE', fontsize=12)\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(models, fontsize=11)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        ax1.text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            bar.get_height(),\n",
        "            f'{bar.get_height():,.0f}',\n",
        "            ha='center',\n",
        "            va='bottom',\n",
        "            fontsize=10\n",
        "        )\n"
      ],
      "metadata": {
        "id": "QSZrPUraOAIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "bars1 = plt.bar(x - width, train_mae, width, label='Train', alpha=0.85)\n",
        "bars2 = plt.bar(x, val_mae, width, label='Validasi', alpha=0.85)\n",
        "bars3 = plt.bar(x + width, test_mae, width, label='Test', alpha=0.85)\n",
        "\n",
        "plt.title('Perbandingan MAE', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Model', fontsize=13)\n",
        "plt.ylabel('MAE', fontsize=13)\n",
        "plt.xticks(x, models, fontsize=12)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            bar.get_height(),\n",
        "            f'{bar.get_height():,.0f}',\n",
        "            ha='center',\n",
        "            va='bottom',\n",
        "            fontsize=10\n",
        "        )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Gu9DJxQuOC3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "bars1 = plt.bar(x - width, train_r2, width, label='Train', alpha=0.85)\n",
        "bars2 = plt.bar(x, val_r2, width, label='Validasi', alpha=0.85)\n",
        "bars3 = plt.bar(x + width, test_r2, width, label='Test', alpha=0.85)\n",
        "\n",
        "plt.title('Perbandingan Nilai R²', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Model', fontsize=13)\n",
        "plt.ylabel('R²', fontsize=13)\n",
        "plt.ylim(0.97, 1.01)\n",
        "plt.xticks(x, models, fontsize=12)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            bar.get_height(),\n",
        "            f'{bar.get_height():.4f}',\n",
        "            ha='center',\n",
        "            va='bottom',\n",
        "            fontsize=10\n",
        "        )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "88BZsJS3OFnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "bars = plt.bar(models, test_mape, alpha=0.85)\n",
        "\n",
        "plt.title('Nilai MAPE Data Test', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Model', fontsize=13)\n",
        "plt.ylabel('MAPE (%)', fontsize=13)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar, val in zip(bars, test_mape):\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        bar.get_height(),\n",
        "        f'{val:.2f}%',\n",
        "        ha='center',\n",
        "        va='bottom',\n",
        "        fontsize=11,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "54RGy66nPjKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "selisih_rmse = [train_rmse[i] - val_rmse[i] for i in range(len(models))]\n",
        "bars = plt.bar(models, selisih_rmse, alpha=0.85)\n",
        "\n",
        "plt.axhline(0, linestyle='--', linewidth=1)\n",
        "plt.title('Analisis Overfitting (RMSE Train - Validasi)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Model', fontsize=13)\n",
        "plt.ylabel('Selisih RMSE', fontsize=13)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar, val in zip(bars, selisih_rmse):\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        bar.get_height(),\n",
        "        f'{val:,.0f}',\n",
        "        ha='center',\n",
        "        va='bottom' if val >= 0 else 'top',\n",
        "        fontsize=11\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4snpNIMOPkkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "ax = plt.subplot(111, polar=True)\n",
        "\n",
        "kategori = ['RMSE', 'MAE', 'MAPE', 'R²', 'Generalisasi']\n",
        "jumlah = len(kategori)\n",
        "\n",
        "sudut = np.linspace(0, 2 * np.pi, jumlah, endpoint=False).tolist()\n",
        "sudut += sudut[:1]\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    nilai = [\n",
        "        1 - test_rmse[i] / max(test_rmse),\n",
        "        1 - test_mae[i] / max(test_mae),\n",
        "        1 - test_mape[i] / max(test_mape),\n",
        "        test_r2[i],\n",
        "        1 - abs(val_rmse[i] - test_rmse[i]) / max(test_rmse)\n",
        "    ]\n",
        "    nilai += nilai[:1]\n",
        "\n",
        "    ax.plot(sudut, nilai, linewidth=2, label=model)\n",
        "    ax.fill(sudut, nilai, alpha=0.15)\n",
        "\n",
        "ax.set_thetagrids(np.degrees(sudut[:-1]), kategori, fontsize=12)\n",
        "ax.set_title('Perbandingan Kinerja Model (Skala 0–1)', fontsize=16, fontweight='bold', pad=25)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8ToiSatpPrAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(22, 7))\n",
        "predictions_list = [lr_test_pred, dt_test_pred, knn_test_pred]\n",
        "r2_test_values  = [lr_test_r2,  dt_test_r2,  knn_test_r2]\n",
        "\n",
        "for ax, pred, model, r2_val in zip(axes, predictions_list, models, r2_test_values):\n",
        "    ax.scatter(y_test, pred, alpha=0.5, s=40)\n",
        "    ax.plot([y_test.min(), y_test.max()],\n",
        "            [y_test.min(), y_test.max()],\n",
        "            'r--', linewidth=2)\n",
        "\n",
        "    ax.set_title(model, fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Harga Aktual', fontsize=12)\n",
        "    ax.set_ylabel('Harga Prediksi', fontsize=12)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    ax.text(\n",
        "        0.05, 0.95,\n",
        "        f'R² = {r2_val:.4f}',\n",
        "        transform=ax.transAxes,\n",
        "        fontsize=12,\n",
        "        verticalalignment='top',\n",
        "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ywcAXL8MPvA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "for i, (pred, model) in enumerate(zip(predictions_list, models)):\n",
        "    residual = y_test - pred\n",
        "\n",
        "    axes[0, i].scatter(pred, residual, alpha=0.5, s=40)\n",
        "    axes[0, i].axhline(0, linestyle='--', linewidth=2)\n",
        "    axes[0, i].set_title(f'Residual Plot - {model}', fontsize=14, fontweight='bold')\n",
        "    axes[0, i].set_xlabel('Prediksi')\n",
        "    axes[0, i].set_ylabel('Residual')\n",
        "    axes[0, i].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1, i].hist(residual, bins=30, alpha=0.7)\n",
        "    axes[1, i].axvline(0, linestyle='--', linewidth=2)\n",
        "    axes[1, i].set_title(\n",
        "        f'Distribusi Residual\\nMean: {residual.mean():,.0f}, Std: {residual.std():,.0f}',\n",
        "        fontsize=13\n",
        "    )\n",
        "    axes[1, i].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LVBu3rq-Pw80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.4 Interpretasi Visualisasi\n",
        "\n",
        "1. Grafik Perbandingan RMSE (Train/Validation/Test):\n",
        "- Membandingkan error pada ketiga dataset secara bersamaan\n",
        "- Model yang baik memiliki nilai RMSE yang konsisten di ketiganya\n",
        "- Gap besar antara Train dan Val/Test mengindikasikan overfitting\n",
        "- Catatan: Train RMSE = 0 untuk KNN adalah normal (lihat penjelasan sebelumnya)\n",
        "\n",
        "2. Grafik R² Score:\n",
        "- Menunjukkan seberapa baik model menjelaskan variasi data target\n",
        "- R² mendekati 1.0 menandakan prediksi yang sangat akurat\n",
        "- R² > 0.9 umumnya dianggap sangat baik untuk masalah regresi\n",
        "\n",
        "3. Grafik MAPE (Mean Absolute Percentage Error):\n",
        "- Menunjukkan rata-rata persentase error prediksi\n",
        "- MAPE < 10% umumnya dianggap akurat\n",
        "- Mudah dikomunikasikan: \"Error rata-rata adalah X% dari harga aktual\"\n",
        "\n",
        "4. Analisis Overfitting (Selisih RMSE Train - Validation):\n",
        "- Nilai negatif besar: Train RMSE jauh lebih kecil dari Val RMSE → kemungkinan overfitting\n",
        "- Nilai mendekati 0: Performa train dan validation seimbang → generalisasi baik\n",
        "- Nilai positif: Train RMSE > Val RMSE → kondisi tidak biasa, mungkin underfitting\n",
        "\n",
        "5. Radar Chart (Spider Plot):\n",
        "- Memberikan perbandingan multi-dimensi dari semua metrik\n",
        "- Model dengan area lebih luas memiliki performa keseluruhan lebih baik\n",
        "- Memudahkan melihat trade-off: model A mungkin unggul di metrik X tapi kalah di metrik Y\n",
        "\n",
        "6. Scatter Plot Actual vs Predicted:\n",
        "- Titik yang dekat dengan garis diagonal menunjukkan prediksi akurat\n",
        "- Penyebaran titik yang merata di sekitar garis menunjukkan model tidak bias\n",
        "- Pola sistematis (melengkung, mengelompok) mengindikasikan model tidak menangkap semua pola\n",
        "\n",
        "7. Residual Analysis:\n",
        "- Residual Plot: Residual (error) harus tersebar random di sekitar garis 0\n",
        "- Pola sistematis pada residual plot mengindikasikan ada pola yang tidak tertangkap\n",
        "- Histogram Residual: Idealnya berbentuk distribusi normal dengan mean ≈ 0\n",
        "- Std residual yang kecil menandakan prediksi yang konsisten\n",
        "\n"
      ],
      "metadata": {
        "id": "kjdRO9O1THIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. KESIMPULAN"
      ],
      "metadata": {
        "id": "mXEt8L_omypN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan serangkaian eksperimen yang telah dilakukan, berikut adalah kesimpulan komprehensif dari penelitian ini:\n",
        "\n",
        "## 9.1 Pengaruh Genetic Algorithm terhadap Performa Model\n",
        "\n",
        "Penerapan Genetic Algorithm (GA) terbukti efektif dalam mengoptimasi model prediksi harga rumah. GA berhasil melakukan:\n",
        "\n",
        "1. Feature Selection Otomatis: GA secara cerdas memilih subset fitur yang paling relevan dari 7 fitur yang tersedia. Hasil menunjukkan bahwa tidak semua fitur diperlukan untuk menghasilkan prediksi optimal.\n",
        "\n",
        "2. Hyperparameter Tuning: Untuk model KNN dan Decision Tree, GA menemukan kombinasi hyperparameter yang optimal tanpa perlu melakukan exhaustive grid search yang memakan waktu.\n",
        "\n",
        "3. Efisiensi Komputasi: Dibandingkan dengan brute-force search, GA dapat menemukan solusi yang baik dalam waktu yang jauh lebih singkat karena prinsip evolusi yang terarah.\n",
        "\n",
        "## 9.2 Perbandingan Kinerja Model\n",
        "\n",
        "Berdasarkan evaluasi pada data uji (test set), model dengan nilai RMSE paling rendah menunjukkan kinerja terbaik. Analisis mendalam menunjukkan:\n",
        "\n",
        "- Linear Regression diharapkan memberikan performa terbaik karena hubungan antara fitur utama (Square_Footage) dan target (House_Price) bersifat hampir perfectly linear (korelasi 0.991)\n",
        "- Model kompleks seperti Decision Tree dan KNN tidak selalu lebih baik jika pola data sudah sederhana (linear)\n",
        "- Trade-off kompleksitas vs akurasi: Model sederhana yang cocok dengan pola data lebih baik daripada model kompleks yang tidak sesuai\n",
        "\n",
        "## 9.3 Analisis Overfitting dan Generalisasi\n",
        "\n",
        "Perbedaan nilai error (RMSE) pada data training, validation, dan test menunjukkan:\n",
        "\n",
        "- Model tidak mengalami overfitting yang signifikan jika gap antara Train dan Val/Test RMSE kecil\n",
        "- Konsistensi antara Val RMSE dan Test RMSE mengindikasikan kemampuan generalisasi yang baik\n",
        "- Penggunaan validation set terpisah untuk fitness GA membantu mencegah overfitting selama optimasi\n",
        "\n",
        "## 9.4 Hasil Feature Selection\n",
        "\n",
        "Hasil feature selection menggunakan GA mengkonfirmasi temuan dari analisis korelasi:\n",
        "\n",
        "- Square_Footage secara konsisten terpilih sebagai fitur paling penting oleh semua model\n",
        "- Fitur-fitur dengan korelasi rendah (< 0.2) cenderung tidak dipilih atau memiliki kontribusi minimal\n",
        "- Hal ini menunjukkan bahwa GA efektif dalam mengidentifikasi fitur yang benar-benar relevan\n",
        "\n",
        "## 9.5 Implikasi Praktis\n",
        "\n",
        "Dari perspektif aplikasi praktis:\n",
        "\n",
        "1. Untuk Deployment: Model terbaik dapat digunakan untuk membantu estimasi harga rumah dalam sistem penilaian properti\n",
        "\n",
        "2. Interpretabilitas: Dominasi Square_Footage memberikan insight bisnis yang jelas: \"Luas bangunan adalah faktor paling menentukan harga rumah dalam dataset ini\"\n",
        "\n",
        "3. Efisiensi Data: Tidak semua fitur perlu dikumpulkan; cukup fokus pada fitur-fitur yang terbukti berpengaruh\n",
        "\n",
        "## 9.6 Rekomendasi\n",
        "\n",
        "Berdasarkan hasil penelitian, direkomendasikan:\n",
        "\n",
        "1. Gunakan model terbaik (berdasarkan Test RMSE terendah) untuk deployment\n",
        "2. Fokus pada fitur-fitur utama yang terpilih oleh GA untuk pengumpulan data di masa depan\n",
        "3. Pertimbangkan Linear Regression sebagai baseline karena kesederhanaannya dan kesesuaiannya dengan pola data\n",
        "4. Monitor performa secara berkala karena pola data properti dapat berubah seiring waktu\n",
        "\n",
        "Kesimpulan Akhir: Penggunaan Genetic Algorithm sebagai metode optimasi terbukti efektif dalam meningkatkan kinerja model prediksi harga rumah. Kombinasi feature selection dan hyperparameter tuning oleh GA menghasilkan model yang akurat, efisien, dan memiliki generalisasi yang baik.\n"
      ],
      "metadata": {
        "id": "EfSA1LyoP1Ry"
      }
    }
  ]
}